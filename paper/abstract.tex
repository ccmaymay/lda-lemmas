Topic models are often represented by top-$m$ word lists for human
interpretation.  The corpus is often lemmatized
so that those representations are not undermined by a proliferation of
words with similar meanings; however, the effect of that pre-processing
on interpretability is generally unmeasured.
We measure the effect of lemmatization on the interpretability of a
latent Dirichlet allocation (LDA) model on Russian Wikipedia
articles.  Using a word intrusion evaluation, we
demonstrate that lemmatization significantly benefits
the interpretability of a topic model on this corpus of morphologically
rich text.
