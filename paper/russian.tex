\documentclass[11pt,letterpaper]{article}
\usepackage{ijcnlp2017}
\usepackage{times}
\usepackage{latexsym}

\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{xspace}

\usepackage{booktabs}

\usepackage[inline,shortlabels]{enumitem}
\setlist*[enumerate,1]{label=$(\arabic*)$}
\setlist*[itemize,1]{label=$\bullet$}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

\renewcommand{\vec}{\boldsymbol}   % optional
\newcommand{\vf}{{\vec{f}}}
\newcommand{\vg}{{\vec{g}}}
\newcommand{\vh}{{\vec{h}}}
\newcommand{\vx}{{\vec{x}}}
\newcommand{\vz}{{\vec{z}}}
\newcommand{\vm}{{\vec{m}}}
\newcommand{\vw}{{\vec{w}}}
\newcommand{\vc}{{\vec{c}}}
\newcommand{\vy}{{\vec{y}}}
\newcommand{\vl}{{\vec{l}}}
\newcommand{\vs}{{\vec{s}}}
\newcommand{\vphi}{{\vec{\phi}}}
\newcommand{\valpha}{{\vec{\alpha}}}
\newcommand{\vxi}{{\vec{\xi}}}

\newcommand{\vmu}{{\vec{\mu}}}
\newcommand{\vtheta}{{\vec{\theta}}}
\newcommand{\veta}{{\vec{\eta}}}
\newcommand{\vomega}{{\vec{\omega}}}
\newcommand{\vpsi}{{\vec{\psi}}}
\newcommand{\vbeta}{{\vec{\beta}}}

\newcommand{\dirac}[2]{\delta_{#1}\left(#2\right)}
\newcommand{\Discrete}{\ensuremath{\mathrm{Discrete}}}
\newcommand{\Dirichlet}{\ensuremath{\mathrm{Dirichlet}}}

\newcommand{\DR}{\ensuremath{\textrm{DR}}}

\newcommand{\wfa}{\textsuperscript{$\star$}\xspace}
\newcommand{\wfb}{\textsuperscript{$\dagger$}\xspace}
\newcommand{\wfc}{\textsuperscript{$\ddagger$}\xspace}
\newcommand{\wfd}{\textsuperscript{$\star\star$}\xspace}

\def\figref#1{Figure~\ref{fig:#1}}
\def\figlabel#1{\label{fig:#1}\label{p:#1}}
\def\Tabref#1{Table~\ref{tab:#1}}
\def\tabref#1{Table~\ref{tab:#1}}
\def\tablabel#1{\label{tab:#1}\label{p:#1}}
\def\Secref#1{Section~\ref{sec:#1}}
\def\secref#1{Section~\ref{sec:#1}}
\def\seclabel#1{\label{sec:#1}\label{p:#1}}
\def\eqref#1{Eq.~\ref{eqn:#1}}
\def\eqrefn#1{\ref{eqn:#1}}
\def\eqsref#1#2{Eqs.~\ref{eqn:#1}-\ref{eqn:#2}}
\def\eqlabel#1{\label{eqn:#1}}
\def\subsp#1{P_{\mbox{{\scriptsize\rm #1}}}}

% Uncomment this line for the final submission:
%\ijcnlpfinalcopy

%  Enter the IJCNLP Paper ID here:
\def\ijcnlppaperid{1087}

\title{Analysis of Morphology in Topic Modeling}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
\author{Chandler May \and Ryan Cotterell \and Benjamin Van Durme \\
    Johns Hopkins University \\
    \texttt{cjmay@jhu.edu ryan.cotterell@gmail.com
    vandurme@cs.jhu.edu}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
    \input{abstract.tex}
\end{abstract}


\section{Introduction}\label{sec:introduction}

Topic modeling is a standard tool in the analysis of large
text corpora. Topic models learn
co-occurrence information about words in the corpus;
words that occur often in the same document are likely to belong to
the same latent topic. In languages with rich inflectional
morphology this information may be masked by the proliferation of
unique tokens with similar meanings.  While lemmatization (or stemming)
is often used to preempt this problem, its effects on a topic model are
generally assumed, not measured.  In this study we establish the first
measurements of the effect of token-based lemmatization on topic models
on a corpus of morphologically rich language.

Syntactic information is not generally considered to exert a strong
force on the thematic nature of a document.  Indeed, for this reason
topic models often make a bag-of-words assumption, discarding the order
of words within a document.  In morphologically rich languages,
however, syntactic information is often encoded in the word form
itself.  This kind of syntactic information may be a nuisance variable
in topic modeling, polluting a topic representation
learned from data~\cite{boydgraber2014}.
For example, consider the Russian name
{\em Putin}: In English, we have a single type that represents in the
concept in all syntactic contexts, whereas in Russian
{\selectlanguage{russian} Путин} appears with various inflections
such as {\selectlanguage{russian}Путина},
{\selectlanguage{russian}Путину}, {\selectlanguage{russian}Путине},
and {\selectlanguage{russian}Путином}. Which form of the name one uses
depends on the syntactic structure of the sentence. Compare
the utterances {{\selectlanguage{russian}мы говорим о Путине} ({\em we
are speaking about Putin}) and {{\selectlanguage{russian}мы
  говорим Путину} ({\em we are speaking to Putin})}: Both sentences
are thematically centered on Putin but two different word forms
are employed.  In particular,
English stop words like prepositions often end up as inflectional
suffixes in Russian, so ``stop words'' may have a greater effect on
topic models on Russian text than they do on topic models on English
text.\footnote{
	Topic models on English are sensitive to stop
	words~\cite{wallach2009,blei2010,eisenstein2011},
	although the degree of sensitivity and prescribed
    resolution are contested~\cite{schofield2017}.
}

In this study, we show that a measure of the interpretability of a
topic model on a morphologically rich text is significantly
improved by lemmatization when a stop-word--filtered vocabulary and
asymmetric prior are used.  In contrast, under an unfiltered vocabulary
and symmetric prior, we find lemmatization has no significant effect.


\section{Morphology and Lemmatization}\label{sec:inflectional}

We study the sensitivity of topic models to variation in the structure
of individual words, specifically
{\em inflectional morphology}, the word-internal
structure that marks syntactically relevant linguistic
properties like person, number, case, and gender.
While inflectional morphology is minimal in English and
virtually non-existent in Chinese, it is prevalent in
the grammars of languages like Russian. In fact, relations that are marked with prepositions in English are often expressed as suffixes in Russian, reducing the number of words in the
sentence. The collection of inflections of the same stem is referred to as a
paradigm.  The Russian noun forms a paradigm with twelve
forms; see the sample paradigm in Table~\ref{tab:paradigm} for an
example.\footnote{
  Note that Table~\ref{tab:paradigm} contains several
  entries that are identical; for example, the singular genitive is the same
  as the singular accusative. This is a common phenomenon known as
  syncretism~\cite{baerman2005syntax}, but it is not universal across
  nouns---many Russian nouns {\em do} make the distinction between
  genitive and accusative in the singular.
}
The Russian verb is even more expressive, having more
than thirty unique forms~\cite{wade2010comprehensive}.

In the tasks of NLP, large paradigms imply an increased token to type
ratio, greatly increasing the number of unknown words. One way to
combat this issue is to {\em lemmatize} the sentence.  A lemmatizer maps each
inflection (an element of the paradigm) to a canonical form known as
the \emph{lemma}, typically the form found in dictionaries
written in the target language.
In this study we use the TreeTagger
lemmatizer~\cite{schmid1994probabilistic},\footnote{
   \url{http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/}
}
estimating its parameters on the Russian corpus described in
\newcite{sharov2011proper}.

\begin{table}
    \centering
  \begin{tabular}{l l l }
      \toprule
                     & Singular & Plural \\ \midrule
    Nominative &  {\selectlanguage{russian}пес} ({\em pyos}) & {\selectlanguage{russian}псы}    ({\em psy})   \\
    Genitive &  {\selectlanguage{russian}пса} ({\em psa}) & {\selectlanguage{russian}псов}    ({\em psov})  \\
    Accusative &  {\selectlanguage{russian}пса} ({\em psa}) & {\selectlanguage{russian}псов}    ({\em psov})  \\
    Dative &  {\selectlanguage{russian}псу} ({\em psu}) & {\selectlanguage{russian}псам}    ({\em psam})  \\
    Locative &  {\selectlanguage{russian}псе} ({\em psye}) & {\selectlanguage{russian}псах}   ({\em psax})  \\
    Instrumental &  {\selectlanguage{russian}псом} ({\em psom}) & {\selectlanguage{russian}псами}  ({\em psami}) \\
      \bottomrule
  \end{tabular}
  \caption{A inflectional paradigm for the Russian word
    {\selectlanguage{russian}пес} ({\em pyos}), meaning ``dog''.  Each
    of the 12 different entries in the table occurs in a distinct
    syntactic context. A lemmatizer canonicalizes these forms to
    single form, which is the nominative singular in, reducing the sparsity present in the corpus.}
    \label{tab:paradigm}
\end{table}


\section{Related Work}\label{sec:related-work}

To measure the effect of lemmatization on topic models we must first
define ``topic model.''  In this study, for comparability with other
work, we restrict our attention to latent Dirichlet allocation
(LDA)~\cite{blei2003}, the canonical Bayesian graphical topic model.
We want to measure the performance of a topic model by its
interpretability, as topic models are best suited to discovering
human-interpretable decompositions of the data~\cite{may2015}.
We note there are more modern but less widely-used topic models than
LDA such as the sparse additive generative
(SAGE) topic model, which explicitly models the background word
distribution and encourages sparse topics~\cite{eisenstein2011}, or the
nested hierarchical Dirichlet process (nHDP) topic model, which
represents topics in a hierarchy and automatically infers its effective
size~\cite{paisley2015}.  These models may render more interpretable
results overall.  Separately, the infinite-vocabulary LDA model has a
prior similar to an $n$-gram model~\cite{zhai2013}, which could be
viewed as loosely encoding beliefs of a concatenative morphology, but
the effect of that prior has not been analyzed in isolation.  However,
we are currently interested in the \emph{relative} impact of
lemmatization on a topic model and we wish for our results to be
applicable across research and industry.  Thus we leave these
alternative topic models as considerations for future work.

Though stemming and lemmatization (a weak form of stemming) have long
been applied in topic modeling
studies~\cite{deerwester1990,hofmann1999,mei2007,nallapati2008,lin2009},
their effect on a topic model was first measured recently, in a
comparison of rule-based and context-based stemmers over four
English corpora~\cite{schofield2016}.
Stemming was found to reduce model fit, negligibly
affect topic coherence, negligibly or negatively affect induced token
cluster consistency, and conflate unrelated words.
Our analysis is complementary: we measure higher-level
interpretability of topics using human judgments on a corpus of
morphologically rich language.

While it has only recently begun to be analyzed in the context of topic
modeling, morphology has been actively investigated in the context of
word embeddings.  The latent topic vectors that topic models discover
have many parallels to continuous embeddings---both are real-valued
representations that stand proxy for (some notion of) lexical semantic
information. Most notably, \newcite{BianGL14} learned
embeddings for individual morphemes jointly within the standard {\sc word2vec}
model \cite{mikolov2013distributed} and \newcite{SoricutO15} used the embeddings
themselves to induce morphological analyzers. Character-level embedding approaches
have also been explored with the express aim of capturing morphology \cite{santos2014learning,LingDBTFAML15}.

\begin{table*}
    \centering
    \begin{tabular}{ll}
        \toprule
        view & topic \\\midrule

        lem & {\selectlanguage{russian}деревня\wfa сельский поселение пункт сельсовет} \\
        non & {\selectlanguage{russian}деревня\wfa деревни\wfa деревне\wfa жителей волости} \\\midrule

        lem & {\selectlanguage{russian}клетка лечение\wfa заболевание\wfb препарат действие} \\
        non & {\selectlanguage{russian}лечения\wfa течение лечение\wfa крови заболевания\wfb} \\\midrule

        lem & {\selectlanguage{russian}японский\wfa япония\wfb корея префектура смотреть} \\
        non & {\selectlanguage{russian}считается японии\wfb японский\wfa посёлок японской\wfa} \\\midrule

        lem & {\selectlanguage{russian}художник\wfa искусство\wfb художественный\wfa картина\wfc выставка\wfd} \\
        non & {\selectlanguage{russian}искусства\wfb музея картины\wfc выставки\wfd выставка\wfd} \\
        \bottomrule
    \end{tabular}
    \caption{Manually-aligned topic pairs: the first topic in each pair
        is from the lemmatized model, the second pair is a semantically
        similar topic in the non-lemmatized model.  Within each pair,
        each of the symbols \wfa, \wfb, \wfc, and \wfd (separately)
        denotes word forms of a shared lemma.
        The lemmatized topic representations are more
        diverse than those of the non-lemmatized topic representations.
        For example, the non-lemmatized version of the first topic
        contains three inflections of the Russian word
        {\selectlanguage{russian}деревня} ({\em village})---successive
        inflectional forms add little or no information to the topic.
    }
    \label{tab:topics}
\end{table*}


\section{Experiments}\label{sec:experiments}

For some pre-specified
number of topics $K$ and Dirichlet concentration hyperparameters
$\veta$ and $\valpha$, the LDA topic model represents a vocabulary as a
set of $K$ i.i.d.\ topics $\vbeta_k$, represents each document as a
an i.i.d.\ mixture over those topics (with mixture weights
$\vtheta_d$), and specifies that each token in a document is
generated by sampling a word type from the document's topic mixture:
\begin{align*}
    \vbeta_k  & \sim \Dirichlet\left(\veta\right) \\
    \vtheta_d & \sim \Dirichlet\left(\valpha\right) \\
    z_{d,n}              & \sim \Discrete\left(\vtheta_d\right) \\
    w_{d,n}              & \sim \Discrete\left(\vbeta_{z_{d,n}}\right)
\end{align*}

Meaningful evaluation of topic models is notoriously
difficult and has received considerable attention in the
literature~\cite{chang2009,wallach2009a,newman2010,mimno2011}.
In general we desire an evaluation metric that correlates with a
human's ability to use the model to explore a large data set,
hence, the interpretability of the model.  In this study we moreover
require an evaluation metric that is comparable across different views
of the same corpus.

With those concerns in mind we choose a \emph{word intrusion}
evaluation:
a human expert is shown one topic at a time, represented
by its top $m$ words (for some small number $m$) in random order, as
well as an additional word (called the \emph{intruder}) randomly placed
among the $m$ topic words~\cite{chang2009}.
The intruder is randomly selected from the set of high-probability
words from other topics in the model.
The expert is tasked with identifying the intruder in each list of
$m + 1$ words.
As in prior work~\cite{chang2009}, we instruct the expert to ignore
syntactic and morphological patterns.

If the model is interpretable, the $m$ words from a topic will be
internally coherent whereas the intruder word is likely to stand out.
Thus a model's interpretability can be quantified by the fraction
of topics for which the expert correctly identifies the intruder.  We
call this value the \emph{detection rate}:
\begin{equation*}
    \DR = \frac{1}{K} \sum_{k=1}^K \dirac{i_k}{\omega_k}
\end{equation*}
where $K$ is the number of topics in the model, $i_k$ is the index
of the intruder in the randomized word list generated from topic $k$,
and $\omega_k$ is the index of the word the expert identified as the
intruder.  This metric is the mean of the
\emph{model precision} metric from prior work~\cite{chang2009}
when one expert is used instead of several non-experts.

Our corpus consists of a dump of Russian Wikipedia articles, dated
November 11, 2015, stripped of their XML markup.
When the lemmatizer did not recognize a word form
its output was replaced with the input word form.\footnote{
    11\% of the 378 million tokens in the raw corpus were
    unrecognized by the lemmatizer.
}

We consider two pre-processing schemes to account for stop words and
other high-frequency terms in the corpus.  First, we compute the
vocabulary as the top 10,000 words by document frequency,\footnote{
    Due to minor implementation concerns the lemmatized and
    non-lemmatized vocabularies consist of the top 9387 and 9531 words
    (respectively) by document frequency.
}
separately for the lemmatized and non-lemmatized data, and
specify an asymmetric prior on each document's topic proportions
$\vtheta$.
We refer to this pre-processing scheme
as the \emph{unfiltered-asymmetric} setting.  The second modeling scheme we
consider uses a vocabulary with high-frequency words filtered out and a
uniform prior on the document-wise topic proportions.
(We refer to this setting as \emph{filtered-symmetric}.)
Specifically, a 10,000 word vocabulary is formed from the
lemmatized data by removing the top 100 words by document frequency
over the corpus and taking the next 10,000.  To determine the
non-lemmatized vocabulary, we map the filtered lemmatized
vocabulary onto all word forms that produce one of those lemmas in
the data.  Finally, observing that some of the uninformative
high-frequency words reappear in this projection, we remove any
of the top 100 words from the lemmatized and non-lemmatized corpora
from this list, producing a non-lemmatized vocabulary of 72,641 words.
This large vocabulary slows learning but fair comparison
requires that we retain the information captured by the lemmatized
vocabulary.

We learn LDA by stochastic variational
inference~\cite{hoffman2013}, initializing the models randomly and
using fixed priors.\footnote{
    In preliminary experiments Gibbs
    sampling with hyper-parameter optimization did not improve
    interpretability.
}
We specify $K = 100$ topics to all models.
Uniform priors with $\eta_v = 0.1$ and
$\alpha_k = 5 / K$ were given to
filtered-symmetric models; non-uniform priors with
$\eta_v = 0.1$, $\alpha_1 = 5$, and $\alpha_k = 5 / (K-1)$
for $k > 1$
were given to unfiltered-asymmetric models.
The local hyperparameters $\valpha$ are informed by mean
document word usage and document length; in particular, we
believe approximately 50\% of the word tokens in the corpus are
uninformative.

The detection rate for both configurations (filtered-symmetric or unfiltered-asymmetric
vocabulary), and the
p-values for one-sided detection rate differences (testing our
hypothesis that the lemmatized models yield higher detection rates than
the non-lemmatized models), are reported in
Table~\ref{tab:detection-rate}.  Word intrusion performance benefits
significantly from lemmatization on a filtered vocabulary and a
symmetric prior.
Further, we observe differences
between use of an asymmetric prior on an unfiltered vocabulary and
use of a symmetric prior on a vocabulary with stop words filtered out.

\begin{table}
  \centering
    \begin{tabular}{rrrrr}
        \toprule
              &              & \multicolumn{2}{c}{$\DR$} &       p-val   \\
        vocab & prior        & non         & lem &         $\Delta$ \\\midrule
        unfilt & asym         &          0.54 &          0.52 &          0.61 \\
        filt & sym & 0.50 & 0.65 & 0.02 \\
        \bottomrule
    \end{tabular}
    \caption{Detection rate for the non-lemmatized (non) and
        lemmatized (lem) models
        and p-values for the one-sided difference tests.
        (filt and unfilt indicate whether or not the vocabulary is
        filtered; sym and asym indicate whether the prior is
        symmetric.)
        The detection rate benefits significantly from lemmatization on
        a filtered vocabulary.}
    \label{tab:detection-rate}
\end{table}

We find that topics from the unfiltered-asymmetric models often contain
stop words despite the first topic receiving half of the prior
probability mass.  Indeed, many topics consist primarily of stop
words, such as the topic {\selectlanguage{russian}и в при с у}.
Hand-aligned topics from the filtered-symmetric models
are shown in Table~\ref{tab:topics}.
There is significant redundancy (multiple inflected word forms of the
same lemma) in the top five words of the non-lemmatized topics, whereas
the diversity of words in the lemmatized topics lends to
interpretation.


\section{Conclusion}\label{sec:conclusion}

We have demonstrated the impact of lemmatization as a pre-processing
step to LDA on Wikipedia articles in Russian.  In particular, we have
verified the intuition that lemmatization can significantly improve the
interpretability of a topic model.
However, we recommend measuring rather than assuming the effect of
lemmatization (or stemming) in a new topic modeling application
context, otherwise stemming as a \emph{post-processing} step as
needed~\cite{schofield2016}.

%\section*{Acknowledgments}\label{sec:ack}
%    We thank the Johns Hopkins Human Language Technology
%    Center of Excellence and the DARPA LORELEI program for providing
%    support.
%    The second author acknowledges support from a DAAD long-term
%    research grant.
%    Any opinions expressed in this work are those of the authors.


\bibliography{russian}
\bibliographystyle{ijcnlp2017}

\end{document}
